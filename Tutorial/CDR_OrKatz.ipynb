{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plot\n",
    "import pylab as p\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import pylab as py\n",
    "import argparse\n",
    "import imutils\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import ImageClass\n",
    "import IPython\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#תיאור הבעיה\n",
    "IPython.display.Image('FIRandImage.JPG')\n",
    "#img = cv2.imread('FIRandImage.JPG')\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#מקורות\n",
    "print 'Infrared Physics & Technology'\n",
    "img = cv2.imread('FIR Journal.png')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print 'IEEE'\n",
    "img = cv2.imread('IEEE.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print 'JNIRS—Journal of Near Infrared Spectroscopy'\n",
    "img = cv2.imread('inferared.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#מאמרים חשובים\n",
    "#webbrowser.open_new(r'file://C:\\Users\\OR-PC\\Desktop\\CodePython\\Infrared Pedestrian Detection Utilizing Entropy-Edge Weighted Local Gradient  Orientation Descriptor.pdf')\n",
    "#webbrowser.open_new(r'file://C:\\Users\\OR-PC\\Desktop\\CodePython\\A Study of the Impact of HOG and LBP Based  Temporal Association On Far Infrared Pedestrian  Detection 2016.pdf')\n",
    "webbrowser.open_new(r'file://C:\\Users\\OR-PC\\Desktop\\CodePython\\Far-Infrared Based Pedestrian Detection for  Driver-Assistance Systems Based on Candidate  Filters, Gradient-Based Feature and Multi-Frame  Approval Matching 2015-2016.pdf')\n",
    "IPython.display.display_pdf('Far-Infrared Based Pedestrian Detection for  Driver-Assistance Systems Based on Candidate  Filters, Gradient-Based Feature and Multi-Frame  Approval Matching 2015-2016.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hog and LBP Example\n",
    "img = cv2.imread('Hog.JPG')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = cv2.imread('Hog2.JPG')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = cv2.imread('lbp.png')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = cv2.imread('AfterHogAndLbp.JPG')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('3.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = cv2.imread('b.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HoG\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread(\"b.jpg\"),cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cell_size = (8, 8)  # h x w in pixels\n",
    "block_size = (2, 2)  # h x w in cells\n",
    "nbins = 9  # number of orientation bins\n",
    "\n",
    "# winSize is the size of the image cropped to an multiple of the cell size\n",
    "hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                  img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                        _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)\n",
    "\n",
    "n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "hog_feats = hog.compute(img)\\\n",
    "               .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                        n_cells[0] - block_size[0] + 1,\n",
    "                        block_size[0], block_size[1], nbins) \\\n",
    "               .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "# hog_feats now contains the gradient amplitudes for each direction,\n",
    "# for each cell of its group for each group. Indexing is by rows then columns.\n",
    "\n",
    "gradients = np.zeros((n_cells[0], n_cells[1], nbins))\n",
    "\n",
    "# count cells (border cells appear less often across overlapping groups)\n",
    "cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "for off_y in range(block_size[0]):\n",
    "    for off_x in range(block_size[1]):\n",
    "        gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                  off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "            hog_feats[:, :, off_y, off_x, :]\n",
    "        cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                   off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "# Average gradients\n",
    "gradients /= cell_count\n",
    "\n",
    "# Preview\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "bin = 5 \n",
    "plt.imshow(gradients[:, :, bin],cmap='gray')\n",
    "plt.show()\n",
    " # angle is 360 / nbins * direction\n",
    "plt.pcolor(gradients[:, :, bin])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "img = cv2.imread('3.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "im = Image.open('3.jpg')  \n",
    "w, h = im.size  \n",
    "colors = im.getcolors(w*h)\n",
    "\n",
    "def hexencode(rgb):\n",
    "    r=rgb[0]\n",
    "    g=rgb[1]\n",
    "    b=rgb[2]\n",
    "    return '#%02x%02x%02x' % (r,g,b)\n",
    "\n",
    "for idx, c in enumerate(colors):\n",
    "        plt.bar(idx, c[0], color=hexencode(c[1]),edgecolor=hexencode(c[1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LBP\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def thresholded(center, pixels):\n",
    "    out = []\n",
    "    for a in pixels:\n",
    "        if a >= center:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return out\n",
    "\n",
    "def get_pixel_else_0(l, idx, idy, default=0):\n",
    "    try:\n",
    "        return l[idx,idy]\n",
    "    except IndexError:\n",
    "        return default\n",
    "    \n",
    "def getLBP(img,transformed_img):\n",
    "    for x in range(0, len(img)):\n",
    "        for y in range(0, len(img[0])):\n",
    "            center        = img[x,y]\n",
    "            top_left      = get_pixel_else_0(img, x-1, y-1)\n",
    "            top_up        = get_pixel_else_0(img, x, y-1)\n",
    "            top_right     = get_pixel_else_0(img, x+1, y-1)\n",
    "            right         = get_pixel_else_0(img, x+1, y )\n",
    "            left          = get_pixel_else_0(img, x-1, y )\n",
    "            bottom_left   = get_pixel_else_0(img, x-1, y+1)\n",
    "            bottom_right  = get_pixel_else_0(img, x+1, y+1)\n",
    "            bottom_down   = get_pixel_else_0(img, x,   y+1 )\n",
    "\n",
    "            values = thresholded(center, [top_left, top_up, top_right, right, bottom_right,\n",
    "                                      bottom_down, bottom_left, left])\n",
    "\n",
    "            weights = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "            res = 0\n",
    "            for a in range(0, len(values)):\n",
    "                res += weights[a] * values[a]\n",
    "            transformed_img.itemset((x,y), res)\n",
    "    \n",
    "print 'Gray Image'\n",
    "img = cv2.imread('b.jpg', 0)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img = cv2.imread('b.jpg', 0)\n",
    "transformed_img = cv2.imread('b.jpg', 0)\n",
    "#transformed_img =gradients[:, :, bin]\n",
    "#transformed_img = img\n",
    "\n",
    "                                    \n",
    "print 'After LBP'\n",
    "getLBP(img,transformed_img)\n",
    "plt.imshow(transformed_img,cmap='gray')\n",
    "plt.show()\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "#print 'After LBP 2'\n",
    "#img2 = transformed_img\n",
    "#getLBP(img2,transformed_img)\n",
    "#plt.imshow(transformed_img,cmap='gray')\n",
    "#plt.show()\n",
    "#hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "#print 'After LBP 3'\n",
    "#img3 = transformed_img\n",
    "#getLBP(img3,transformed_img)\n",
    "#plt.imshow(transformed_img,cmap='gray')\n",
    "#plt.show()\n",
    "#hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "\n",
    "print 'After HoG'\n",
    "img_hog = gradients[:, :, bin]\n",
    "plt.imshow(img_hog,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print 'After HoG and LBP'\n",
    "transformed_img_Hog =gradients[:, :, bin]\n",
    "getLBP(img_hog,transformed_img_Hog)\n",
    "plt.imshow(transformed_img_Hog,cmap='gray')\n",
    "plt.show()\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "print 'Histogram After HoG and LBP'\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(transformed_img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([-5,258])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageClass.HiPassFileter(transformed_img)\n",
    "#ImageClass.Jet(transformed_img)\n",
    "#ImageClass.Dofft(transformed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "im = cv2.imread('3.jpg')\n",
    "im = np.float32(im) / 255.0\n",
    "gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "ImageClass.HiPassFileter(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageClass.Dofft(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageClass.Jet(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "import itertools as it\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plot\n",
    "import pylab as p\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import pylab as py\n",
    "import argparse\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector( cv2.HOGDescriptor_getDefaultPeopleDetector() )\n",
    "def inside(r, q):\n",
    "    rx, ry, rw, rh = r\n",
    "    qx, qy, qw, qh = q\n",
    "    return rx > qx and ry > qy and rx + rw < qx + qw and ry + rh < qy + qh\n",
    "def draw_detections(img, rects, thickness = 1):\n",
    "    for x, y, w, h in rects:\n",
    "        pad_w, pad_h = int(0.15*w), int(0.05*h)\n",
    "        cv2.rectangle(img, (x+pad_w, y+pad_h), (x+w-pad_w, y+h-pad_h), (0, 255, 0), thickness)\n",
    "def Pedestrian(img):\n",
    "    found, w = hog.detectMultiScale(img, winStride=(8,8), padding=(32,32), scale=1.05)\n",
    "    found_filtered = []\n",
    "    for ri, r in enumerate(found):\n",
    "        for qi, q in enumerate(found):\n",
    "            if ri != qi and inside(r, q):\n",
    "                break\n",
    "        else:\n",
    "            found_filtered.append(r)\n",
    "    draw_detections(img, found)\n",
    "    draw_detections(img, found_filtered, 3)\n",
    "    ch = 0xFF & cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('3.jpg')\n",
    "Pedestrian(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('5.avi')\n",
    "car_cascade = cv2.CascadeClassifier('car/cars.xml')\n",
    "#height = int(cap.get(4))\n",
    "#width = int(cap.get(3)) \n",
    "#out = cv2.VideoWriter('output17.avi', -1, 20.0, (width,      height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-399e5fef7eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcar_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frames = cap.read()\n",
    "    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.1, 1)\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frames,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.imshow('video2', frames)\n",
    "        cv2.imshow('videoGray',gray)\n",
    "        #out.write(frames)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('pymle_cover_double_small.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "url = 'http://scikit-learn.org/stable/modules/svm.html'\n",
    "webbrowser.open_new_tab(url + 'doc/')\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full Code SVM python gitHub\n",
    "url = 'https://github.com/rasbt/python-machine-learning-book'\n",
    "webbrowser.open_new_tab(url + 'doc/')\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x78ef9b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from numpy import array   \n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('5.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "gray1 = cv2.Canny(img, 70, 50)\n",
    "cv2.imwrite('gray1.png', gray1)\n",
    "img2 = cv2.imread('gray1.png')\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import ImageClass\n",
    "image = cv2.imread('5.jpg')\n",
    "ImageClass.SVM_Example(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Example\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "trainData = np.random.randint(0,100,(25,2)).astype(np.float32)\n",
    "responses = np.random.randint(0,2,(25,1)).astype(np.float32)\n",
    "red = trainData[responses.ravel()==0]\n",
    "plt.scatter(red[:,0],red[:,1],80,'r','^')\n",
    "blue = trainData[responses.ravel()==1]\n",
    "plt.scatter(blue[:,0],blue[:,1],80,'b','s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ImageClass\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector( cv2.HOGDescriptor_getDefaultPeopleDetector() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('5.avi')\n",
    "cap2 = cv2.VideoCapture('5.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "height = int(cap.get(4))\n",
    "width = int(cap.get(3)) \n",
    "out = cv2.VideoWriter('output5.avi', -1, 20.0, (width,      height))\n",
    "while(cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.Canny(img, 70, 50)\n",
    "    found, w = hog.detectMultiScale(img, winStride=(8,8), padding=(8,8), scale=1.05)\n",
    "    found_filtered = []\n",
    "    for ri, r in enumerate(found):\n",
    "        for qi, q in enumerate(found):\n",
    "            if ri != qi and inside(r, q):\n",
    "                break\n",
    "        else:\n",
    "            found_filtered.append(r)\n",
    "    ImageClass.draw_detections(img, found)\n",
    "    ImageClass.draw_detections(img, found_filtered, 3)\n",
    "    cv2.imshow('frame',img)\n",
    "    out.write(gray1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
